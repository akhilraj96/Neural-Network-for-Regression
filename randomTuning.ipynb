{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for solving regression problem: Hyperparameter tuning using RandomizedSearchCV\n",
    "Author: Akhil Raj\n",
    "\n",
    "This notebook is for turning each hyperparameter using cross-validation in a deep learning model, And thus finding the best hyperparameter values.\n",
    "\n",
    "Methodology:-\n",
    "\n",
    "A default model is defined as base model. For each hyperparamter, values is varied and the model is trained. 5-fold cross-validation is used with RandomizedSearchCV to find best performing set of values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "Tensorflow and Keras is used to build deep neural networks for solving the regression problem. Scikit-learn is used for data pre-processing, train-test split and evaluating the performance of the model. Matplotlib is used for plotting the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading data\n",
    "\n",
    "Loading data using pandas and using standard scaling on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_kcHouse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>age</th>\n",
       "      <th>reno_age</th>\n",
       "      <th>reno_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  180000.0         2       1.00          770     10000     1.0           0   \n",
       "2  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "3  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "4  257500.0         3       2.25         1715      6819     2.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  sqft_living15  \\\n",
       "0     0          3      7        1180              0           1340   \n",
       "1     0          3      6         770              0           2720   \n",
       "2     0          5      7        1050            910           1360   \n",
       "3     0          3      8        1680              0           1800   \n",
       "4     0          3      7        1715              0           2238   \n",
       "\n",
       "   sqft_lot15  age  reno_age  reno_flag  \n",
       "0        5650   59        59          0  \n",
       "1        8062   82        82          0  \n",
       "2        5000   49        49          0  \n",
       "3        7503   28        28          0  \n",
       "4        6819   19        19          0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main= df.copy()\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A detailed exploratory data analysis was performed on the data. Please refer EDA_kcHouse notebook to learn more about the insights on data and feature selection.\n",
    "\n",
    "Here, the Target variable **Price** is an economic variable. To represent Vertical changes in prices related to various attributes, Logarithmic scale is used. Reference: https://www.visualizingeconomics.com/blog/2016/8/5/real-growth-in-us-housing-prices-log-scale \n",
    "\n",
    "So converting the price to log scale.\n",
    "\n",
    "The model predictions can be converted to normal range by taking the exponential of predicted values.\n",
    "\n",
    "Train-Test split is 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_main[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "                                                       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "                                                       'sqft_basement', 'sqft_living15', 'sqft_lot15', 'age',\n",
    "                                                       'reno_age', 'reno_flag']],   \n",
    "                                                    df_main[['price']].apply(np.log),   \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>age</th>\n",
       "      <th>reno_age</th>\n",
       "      <th>reno_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.559642</td>\n",
       "      <td>-0.429099</td>\n",
       "      <td>-0.967696</td>\n",
       "      <td>-0.284067</td>\n",
       "      <td>-0.890471</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.24467</td>\n",
       "      <td>2.487529</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>-0.647077</td>\n",
       "      <td>-0.653487</td>\n",
       "      <td>-0.194373</td>\n",
       "      <td>-0.301564</td>\n",
       "      <td>1.674382</td>\n",
       "      <td>1.677821</td>\n",
       "      <td>-0.067254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.386408</td>\n",
       "      <td>1.753886</td>\n",
       "      <td>1.087562</td>\n",
       "      <td>-0.283810</td>\n",
       "      <td>0.963170</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>3.46569</td>\n",
       "      <td>-0.635179</td>\n",
       "      <td>1.429489</td>\n",
       "      <td>0.575127</td>\n",
       "      <td>1.011825</td>\n",
       "      <td>0.186617</td>\n",
       "      <td>-0.143362</td>\n",
       "      <td>-0.668136</td>\n",
       "      <td>-0.666793</td>\n",
       "      <td>-0.067254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.386408</td>\n",
       "      <td>-0.429099</td>\n",
       "      <td>-0.672929</td>\n",
       "      <td>-0.760557</td>\n",
       "      <td>0.963170</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.24467</td>\n",
       "      <td>-0.635179</td>\n",
       "      <td>0.446166</td>\n",
       "      <td>-1.054479</td>\n",
       "      <td>0.648018</td>\n",
       "      <td>-0.760889</td>\n",
       "      <td>-0.714850</td>\n",
       "      <td>-1.472284</td>\n",
       "      <td>-1.471660</td>\n",
       "      <td>-0.067254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786826</td>\n",
       "      <td>-0.065268</td>\n",
       "      <td>0.614312</td>\n",
       "      <td>-0.087352</td>\n",
       "      <td>-0.890471</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.24467</td>\n",
       "      <td>-0.635179</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>-0.618981</td>\n",
       "      <td>2.292834</td>\n",
       "      <td>0.501348</td>\n",
       "      <td>-0.347404</td>\n",
       "      <td>0.485641</td>\n",
       "      <td>0.488017</td>\n",
       "      <td>-0.067254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.386408</td>\n",
       "      <td>0.662394</td>\n",
       "      <td>0.425012</td>\n",
       "      <td>-0.449411</td>\n",
       "      <td>0.963170</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.24467</td>\n",
       "      <td>-0.635179</td>\n",
       "      <td>-0.537157</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>-0.653487</td>\n",
       "      <td>0.733256</td>\n",
       "      <td>-0.542254</td>\n",
       "      <td>-0.947840</td>\n",
       "      <td>-0.946747</td>\n",
       "      <td>-0.067254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  sqft_lot    floors  waterfront     view  \\\n",
       "0 -1.559642  -0.429099    -0.967696 -0.284067 -0.890471   -0.011425 -0.24467   \n",
       "1 -0.386408   1.753886     1.087562 -0.283810  0.963170   -0.011425  3.46569   \n",
       "2 -0.386408  -0.429099    -0.672929 -0.760557  0.963170   -0.011425 -0.24467   \n",
       "3  0.786826  -0.065268     0.614312 -0.087352 -0.890471   -0.011425 -0.24467   \n",
       "4 -0.386408   0.662394     0.425012 -0.449411  0.963170   -0.011425 -0.24467   \n",
       "\n",
       "   condition     grade  sqft_above  sqft_basement  sqft_living15  sqft_lot15  \\\n",
       "0   2.487529 -0.537157   -0.647077      -0.653487      -0.194373   -0.301564   \n",
       "1  -0.635179  1.429489    0.575127       1.011825       0.186617   -0.143362   \n",
       "2  -0.635179  0.446166   -1.054479       0.648018      -0.760889   -0.714850   \n",
       "3  -0.635179 -0.537157   -0.618981       2.292834       0.501348   -0.347404   \n",
       "4  -0.635179 -0.537157    0.799900      -0.653487       0.733256   -0.542254   \n",
       "\n",
       "        age  reno_age  reno_flag  \n",
       "0  1.674382  1.677821  -0.067254  \n",
       "1 -0.668136 -0.666793  -0.067254  \n",
       "2 -1.472284 -1.471660  -0.067254  \n",
       "3  0.485641  0.488017  -0.067254  \n",
       "4 -0.947840 -0.946747  -0.067254  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Scaler object\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# apply the transformation to the training data\n",
    "x_train_std = std_scaler.fit_transform(x_train) \n",
    "\n",
    "# apply the transformation to the testing data\n",
    "x_test_std = std_scaler.transform(x_test) # but we only transform our testing data with already fit scaler\n",
    "\n",
    "# convert resulting array back to dataframe\n",
    "x_test_std_df = pd.DataFrame(x_test_std, columns = x_train.columns)\n",
    "\n",
    "x_test_std_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Functions and Base model\n",
    "A base model is defined as the base model with name : **model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer,lr):\n",
    "    \"\"\"\n",
    "    Map and initialise optimizers with learning rate\n",
    "    \n",
    "    \"\"\"\n",
    "    if optimizer == 'adadelta':\n",
    "        opt = tf.keras.optimizers.Adadelta(learning_rate=lr)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == 'adamax':\n",
    "        opt = tf.keras.optimizers.Adamax(learning_rate=lr)\n",
    "    elif optimizer == 'ftrl':\n",
    "        opt = tf.keras.optimizers.Ftrl(learning_rate=lr)\n",
    "    elif optimizer == 'nadam':\n",
    "        opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(learning_rate=0.1,activation_fn='relu',no_layers=1,no_neurons=32,loss='huber',optimizer='ftrl'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,activation=activation_fn))\n",
    "    for _ in range(no_layers):\n",
    "        model.add(Dense(no_neurons,activation=activation_fn))\n",
    "    model.add(Dense(1, activation = activation_fn))\n",
    "    opt = get_optimizer(optimizer,learning_rate)\n",
    "    model.compile(optimizer=opt,loss=loss,metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Create a KerasRegressor\n",
    "model = KerasRegressor(build_fn = base_model,\n",
    "                       verbose = 0, epochs=40, \n",
    "                       batch_size = 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .......................no_layers=1;, score=0.602 total time=   6.0s\n",
      "[CV 2/5] END .......................no_layers=1;, score=0.597 total time=   5.8s\n",
      "[CV 3/5] END .......................no_layers=1;, score=0.609 total time=   5.8s\n",
      "[CV 4/5] END .......................no_layers=1;, score=0.601 total time=   6.0s\n",
      "[CV 5/5] END .......................no_layers=1;, score=0.590 total time=   6.3s\n",
      "[CV 1/5] END .......................no_layers=2;, score=0.632 total time=   6.5s\n",
      "[CV 2/5] END .......................no_layers=2;, score=0.626 total time=   6.4s\n",
      "[CV 3/5] END .......................no_layers=2;, score=0.635 total time=   6.2s\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_1={'no_layers':[1,2,3,4]}\n",
    "\n",
    "random_search_1 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_1,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_1 = random_search_1.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_1.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_1.best_params_)\n",
    "\n",
    "nh = random_search_results_1.best_params_\n",
    "\n",
    "y_test_1= random_search_results_1.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_1, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_1, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_1, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_layers': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ........no_layers=2, no_neurons=24;, score=0.627 total time=   6.4s\n",
      "[CV 2/5] END ........no_layers=2, no_neurons=24;, score=0.624 total time=   7.0s\n",
      "[CV 3/5] END ........no_layers=2, no_neurons=24;, score=0.629 total time=   6.5s\n",
      "[CV 4/5] END ........no_layers=2, no_neurons=24;, score=0.620 total time=   6.5s\n",
      "[CV 5/5] END ........no_layers=2, no_neurons=24;, score=0.610 total time=   6.6s\n",
      "[CV 1/5] END ........no_layers=2, no_neurons=32;, score=0.632 total time=   6.6s\n",
      "[CV 2/5] END ........no_layers=2, no_neurons=32;, score=0.626 total time=   6.7s\n",
      "[CV 3/5] END ........no_layers=2, no_neurons=32;, score=0.635 total time=   6.9s\n",
      "[CV 4/5] END ........no_layers=2, no_neurons=32;, score=0.611 total time=   6.5s\n",
      "[CV 5/5] END ........no_layers=2, no_neurons=32;, score=0.620 total time=   6.6s\n",
      "[CV 1/5] END ........no_layers=2, no_neurons=40;, score=0.628 total time=   6.9s\n",
      "[CV 2/5] END ........no_layers=2, no_neurons=40;, score=0.627 total time=   6.9s\n",
      "[CV 3/5] END ........no_layers=2, no_neurons=40;, score=0.638 total time=   6.6s\n",
      "[CV 4/5] END ........no_layers=2, no_neurons=40;, score=0.615 total time=   6.5s\n",
      "[CV 5/5] END ........no_layers=2, no_neurons=40;, score=0.618 total time=   6.5s\n",
      "[CV 1/5] END ........no_layers=2, no_neurons=48;, score=0.618 total time=   6.6s\n",
      "[CV 2/5] END ........no_layers=2, no_neurons=48;, score=0.607 total time=   6.6s\n",
      "[CV 3/5] END ........no_layers=2, no_neurons=48;, score=0.626 total time=   6.6s\n",
      "[CV 4/5] END ........no_layers=2, no_neurons=48;, score=0.621 total time=   6.6s\n",
      "[CV 5/5] END ........no_layers=2, no_neurons=48;, score=0.601 total time=   6.8s\n",
      "Best Score:  0.6252736448785778 and Best Params:  {'no_neurons': 40, 'no_layers': 2}\n",
      "MAE: 0.2217203464827165\n",
      "MSE: 0.07814788851098738\n",
      "RMSE: 0.27954943840220353\n",
      "R2: 0.41585902797026797\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_2={'no_layers':[nh['no_layers']],'no_neurons':[24,32,40,48]}\n",
    "\n",
    "random_search_2 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_2,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_2 = random_search_2.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_2.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_2.best_params_)\n",
    "\n",
    "nn = random_search_results_2.best_params_\n",
    "\n",
    "y_test_2= random_search_results_2.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_2, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_2, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_2, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_neurons': 40, 'no_layers': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=sgd;, score=0.579 total time=   6.0s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=sgd;, score=0.613 total time=   5.8s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=sgd;, score=0.351 total time=   5.8s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=sgd;, score=0.383 total time=   6.1s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=sgd;, score=0.462 total time=   6.3s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=adadelta;, score=0.593 total time=   6.7s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=adadelta;, score=0.567 total time=   6.8s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=adadelta;, score=0.605 total time=   6.5s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=adadelta;, score=-0.074 total time=   6.8s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=adadelta;, score=-0.063 total time=   7.0s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=adagrad;, score=0.622 total time=   6.3s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=adagrad;, score=0.615 total time=   6.4s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=adagrad;, score=0.606 total time=   6.1s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=adagrad;, score=0.615 total time=   6.4s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=adagrad;, score=0.603 total time=   6.1s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=adam;, score=0.513 total time=   7.0s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=adam;, score=0.456 total time=   7.0s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=adam;, score=0.461 total time=   6.6s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=adam;, score=0.333 total time=   6.6s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=adam;, score=0.358 total time=   6.8s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=adamax;, score=0.525 total time=   6.7s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=adamax;, score=0.216 total time=   6.3s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=adamax;, score=0.603 total time=   6.3s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=adamax;, score=0.601 total time=   6.4s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=adamax;, score=0.567 total time=   6.4s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.628 total time=   6.7s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.627 total time=   6.8s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.638 total time=   6.7s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.615 total time=   6.7s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.618 total time=   6.6s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=nadam;, score=0.344 total time=   8.0s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=nadam;, score=0.432 total time=   7.8s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=nadam;, score=-0.001 total time=   7.7s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=nadam;, score=0.412 total time=   7.7s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=nadam;, score=0.506 total time=   7.9s\n",
      "[CV 1/5] END no_layers=2, no_neurons=40, optimizer=rmsprop;, score=-0.015 total time=   6.6s\n",
      "[CV 2/5] END no_layers=2, no_neurons=40, optimizer=rmsprop;, score=-0.033 total time=   6.9s\n",
      "[CV 3/5] END no_layers=2, no_neurons=40, optimizer=rmsprop;, score=-0.006 total time=   7.0s\n",
      "[CV 4/5] END no_layers=2, no_neurons=40, optimizer=rmsprop;, score=-0.022 total time=   6.8s\n",
      "[CV 5/5] END no_layers=2, no_neurons=40, optimizer=rmsprop;, score=-0.007 total time=   7.1s\n",
      "Best Score:  0.6252736448785778 and Best Params:  {'optimizer': 'ftrl', 'no_neurons': 40, 'no_layers': 2}\n",
      "MAE: 0.2217203464827165\n",
      "MSE: 0.07814788851098738\n",
      "RMSE: 0.27954943840220353\n",
      "R2: 0.41585902797026797\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_3={'no_layers':[nh['no_layers']],'no_neurons':[nn['no_neurons']],'optimizer':['sgd','adadelta','adagrad','adam','adamax','ftrl','nadam','rmsprop']}\n",
    "\n",
    "random_search_3 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_3,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_3 = random_search_3.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_3.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_3.best_params_)\n",
    "\n",
    "op = random_search_results_3.best_params_\n",
    "\n",
    "y_test_3= random_search_results_3.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_3, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_3, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_3, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl', 'no_neurons': 40, 'no_layers': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END learning_rate=0.001, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-24.478 total time=   7.0s\n",
      "[CV 2/5] END learning_rate=0.001, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-22.563 total time=   6.7s\n",
      "[CV 3/5] END learning_rate=0.001, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-23.126 total time=   6.6s\n",
      "[CV 4/5] END learning_rate=0.001, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-23.298 total time=   6.7s\n",
      "[CV 5/5] END learning_rate=0.001, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-26.024 total time=   6.8s\n",
      "[CV 1/5] END learning_rate=0.01, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.599 total time=   7.1s\n",
      "[CV 2/5] END learning_rate=0.01, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.589 total time=   6.7s\n",
      "[CV 3/5] END learning_rate=0.01, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.612 total time=   6.7s\n",
      "[CV 4/5] END learning_rate=0.01, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.567 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.01, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.593 total time=   6.7s\n",
      "[CV 1/5] END learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.628 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.627 total time=   6.6s\n",
      "[CV 3/5] END learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.638 total time=   6.8s\n",
      "[CV 4/5] END learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.615 total time=   6.7s\n",
      "[CV 5/5] END learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.618 total time=   6.7s\n",
      "Best Score:  0.6252736448785778 and Best Params:  {'optimizer': 'ftrl', 'no_neurons': 40, 'no_layers': 2, 'learning_rate': 0.1}\n",
      "MAE: 0.2217203464827165\n",
      "MSE: 0.07814788851098738\n",
      "RMSE: 0.27954943840220353\n",
      "R2: 0.41585902797026797\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_4={'no_layers':[nh['no_layers']],'no_neurons':[nn['no_neurons']],'optimizer':[op['optimizer']],'learning_rate':[0.001,0.01,0.1]}\n",
    "\n",
    "random_search_4 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_4,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_4 = random_search_4.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_4.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_4.best_params_)\n",
    "\n",
    "lr = random_search_results_4.best_params_\n",
    "\n",
    "y_test_4= random_search_results_4.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_4, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_4, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_4, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_4, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl', 'no_neurons': 40, 'no_layers': 2, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.628 total time=   6.7s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.627 total time=   6.7s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.638 total time=   6.8s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.615 total time=   6.7s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.618 total time=   7.0s\n",
      "[CV 1/5] END activation_fn=sigmoid, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-681.678 total time=   6.6s\n",
      "[CV 2/5] END activation_fn=sigmoid, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-687.295 total time=   6.6s\n",
      "[CV 3/5] END activation_fn=sigmoid, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.402 total time=   6.7s\n",
      "[CV 4/5] END activation_fn=sigmoid, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-686.106 total time=   6.9s\n",
      "[CV 5/5] END activation_fn=sigmoid, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.965 total time=   6.6s\n",
      "[CV 1/5] END activation_fn=softmax, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-681.676 total time=   7.2s\n",
      "[CV 2/5] END activation_fn=softmax, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-687.293 total time=   7.0s\n",
      "[CV 3/5] END activation_fn=softmax, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.400 total time=   7.1s\n",
      "[CV 4/5] END activation_fn=softmax, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-686.104 total time=   7.2s\n",
      "[CV 5/5] END activation_fn=softmax, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.963 total time=   7.0s\n",
      "[CV 1/5] END activation_fn=softplus, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.566 total time=   7.6s\n",
      "[CV 2/5] END activation_fn=softplus, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.574 total time=   7.4s\n",
      "[CV 3/5] END activation_fn=softplus, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.583 total time=   7.2s\n",
      "[CV 4/5] END activation_fn=softplus, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.577 total time=   7.3s\n",
      "[CV 5/5] END activation_fn=softplus, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.559 total time=   7.3s\n",
      "[CV 1/5] END activation_fn=softsign, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-683.555 total time=   7.0s\n",
      "[CV 2/5] END activation_fn=softsign, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-689.190 total time=   6.7s\n",
      "[CV 3/5] END activation_fn=softsign, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-673.248 total time=   6.5s\n",
      "[CV 4/5] END activation_fn=softsign, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-687.987 total time=   6.9s\n",
      "[CV 5/5] END activation_fn=softsign, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-673.806 total time=   6.8s\n",
      "[CV 1/5] END activation_fn=tanh, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-681.677 total time=   7.1s\n",
      "[CV 2/5] END activation_fn=tanh, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-687.294 total time=   6.7s\n",
      "[CV 3/5] END activation_fn=tanh, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.400 total time=   6.7s\n",
      "[CV 4/5] END activation_fn=tanh, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-686.104 total time=   6.8s\n",
      "[CV 5/5] END activation_fn=tanh, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=-671.964 total time=   7.4s\n",
      "[CV 1/5] END activation_fn=selu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.610 total time=   7.0s\n",
      "[CV 2/5] END activation_fn=selu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.601 total time=   6.8s\n",
      "[CV 3/5] END activation_fn=selu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.613 total time=   6.9s\n",
      "[CV 4/5] END activation_fn=selu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.608 total time=   6.6s\n",
      "[CV 5/5] END activation_fn=selu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.606 total time=   6.9s\n",
      "[CV 1/5] END activation_fn=elu, learning_rate=0.1, no_layers=2, no_neurons=40, optimizer=ftrl;, score=0.605 total time=   7.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Akhil\\Documents\\Study\\COMP534Applied_AI\\Assignments\\Assignment 2\\test.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=1'>2</a>\u001b[0m params_5\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mno_layers\u001b[39m\u001b[39m'\u001b[39m:[nh[\u001b[39m'\u001b[39m\u001b[39mno_layers\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=2'>3</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mno_neurons\u001b[39m\u001b[39m'\u001b[39m:[nn[\u001b[39m'\u001b[39m\u001b[39mno_neurons\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=3'>4</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m:[op[\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=4'>5</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m:[lr[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=5'>6</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mactivation_fn\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msoftplus\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msoftsign\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mselu\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39melu\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=7'>8</a>\u001b[0m random_search_5 \u001b[39m=\u001b[39m RandomizedSearchCV(model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=8'>9</a>\u001b[0m                                    param_distributions \u001b[39m=\u001b[39m params_5,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=9'>10</a>\u001b[0m                                    cv \u001b[39m=\u001b[39m KFold(\u001b[39m5\u001b[39m),verbose\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=10'>11</a>\u001b[0m random_search_results_5 \u001b[39m=\u001b[39m random_search_5\u001b[39m.\u001b[39;49mfit(x_train_std, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Score: \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=13'>14</a>\u001b[0m       random_search_results_5\u001b[39m.\u001b[39mbest_score_,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=14'>15</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mand Best Params: \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=15'>16</a>\u001b[0m       random_search_results_5\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Akhil/Documents/Study/COMP534Applied_AI/Assignments/Assignment%202/test.ipynb#ch0000033?line=17'>18</a>\u001b[0m af \u001b[39m=\u001b[39m random_search_results_5\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1763'>1764</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1764'>1765</a>\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1765'>1766</a>\u001b[0m     evaluate_candidates(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1766'>1767</a>\u001b[0m         ParameterSampler(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1767'>1768</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1768'>1769</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=1769'>1770</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=677'>678</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=678'>679</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=679'>680</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=681'>682</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=682'>683</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/sklearn/model_selection/_validation.py?line=683'>684</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:162\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/wrappers/scikit_learn.py?line=158'>159</a>\u001b[0m fit_args \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_sk_params(Sequential\u001b[39m.\u001b[39mfit))\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/wrappers/scikit_learn.py?line=159'>160</a>\u001b[0m fit_args\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/wrappers/scikit_learn.py?line=161'>162</a>\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/wrappers/scikit_learn.py?line=163'>164</a>\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1176'>1177</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1181'>1182</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1184'>1185</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/keras/engine/training.py?line=1185'>1186</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=881'>882</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=3035'>3036</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=3036'>3037</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=3037'>3038</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=3038'>3039</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=3039'>3040</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1966'>1967</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1967'>1968</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=1968'>1969</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Akhil/.conda/envs/tensorflow/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_5={'no_layers':[nh['no_layers']],\n",
    "            'no_neurons':[nn['no_neurons']],\n",
    "            'optimizer':[op['optimizer']],\n",
    "            'learning_rate':[lr['learning_rate']],\n",
    "            'activation_fn':['relu','sigmoid','softmax','softplus','softsign','tanh','selu','elu']}\n",
    "\n",
    "random_search_5 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_5,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_5 = random_search_5.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_5.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_5.best_params_)\n",
    "\n",
    "af = random_search_results_5.best_params_\n",
    "\n",
    "y_test_5= random_search_results_5.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_5, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_5, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_5, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl',\n",
       " 'no_neurons': 16,\n",
       " 'no_layers': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'activation_fn': 'relu'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.566 total time=   6.7s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.533 total time=   6.7s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.558 total time=   6.7s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.566 total time=   7.9s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.583 total time=   7.4s\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.573 total time=   6.8s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.592 total time=   7.6s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.595 total time=   7.7s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.583 total time=   7.2s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.534 total time=   7.6s\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_percentage_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.355 total time=   7.4s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_percentage_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.539 total time=   7.7s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_percentage_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.604 total time=   7.3s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_percentage_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.553 total time=   7.8s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=mean_absolute_percentage_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.568 total time=   7.5s\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_logarithmic_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.517 total time=   9.2s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_logarithmic_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.594 total time=   7.3s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_logarithmic_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.592 total time=   6.5s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_logarithmic_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.587 total time=   6.5s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=mean_squared_logarithmic_error, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.575 total time=   6.3s\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=log_cosh, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.603 total time=   6.2s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=log_cosh, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.591 total time=   6.1s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=log_cosh, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.593 total time=   6.1s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=log_cosh, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.607 total time=   6.9s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=log_cosh, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.600 total time=   6.2s\n",
      "[CV 1/5] END activation_fn=relu, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.608 total time=   6.4s\n",
      "[CV 2/5] END activation_fn=relu, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.582 total time=   6.7s\n",
      "[CV 3/5] END activation_fn=relu, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.602 total time=   6.8s\n",
      "[CV 4/5] END activation_fn=relu, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.608 total time=   7.1s\n",
      "[CV 5/5] END activation_fn=relu, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.605 total time=   7.2s\n",
      "Best Score:  0.6011488927605795 and Best Params:  {'optimizer': 'ftrl', 'no_neurons': 16, 'no_layers': 2, 'loss': 'huber', 'learning_rate': 0.1, 'activation_fn': 'relu'}\n",
      "MAE: 0.2191794219071851\n",
      "MSE: 0.07707765463776199\n",
      "RMSE: 0.27762862719424664\n",
      "R2: 0.4855355037690554\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_6={'no_layers':[nh['no_layers']],\n",
    "            'no_neurons':[nn['no_neurons']],\n",
    "            'optimizer':[op['optimizer']],\n",
    "            'learning_rate':[lr['learning_rate']],\n",
    "            'activation_fn':[af['activation_fn']],\n",
    "            'loss':['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error','mean_squared_logarithmic_error','log_cosh','huber']}\n",
    "\n",
    "random_search_6 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_6,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_6 = random_search_6.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_6.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_6.best_params_)\n",
    "\n",
    "lo = random_search_results_6.best_params_\n",
    "\n",
    "y_test_6= random_search_results_6.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_6, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_6, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_6, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_6, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl',\n",
       " 'no_neurons': 16,\n",
       " 'no_layers': 2,\n",
       " 'loss': 'huber',\n",
       " 'learning_rate': 0.1,\n",
       " 'activation_fn': 'relu'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Batch Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END activation_fn=relu, batch_size=16, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.574 total time=  17.5s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=16, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.529 total time=  18.5s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=16, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.605 total time=  17.4s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=16, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.614 total time=  17.1s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=16, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.617 total time=  17.8s\n",
      "[CV 1/5] END activation_fn=relu, batch_size=32, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.552 total time=   8.9s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=32, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.400 total time=   9.1s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=32, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.577 total time=   9.0s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=32, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.597 total time=   9.2s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=32, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.603 total time=   9.3s\n",
      "[CV 1/5] END activation_fn=relu, batch_size=64, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.614 total time=   4.9s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=64, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.609 total time=   5.3s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=64, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.623 total time=   4.9s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=64, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   4.8s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=64, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   4.8s\n",
      "Best Score:  0.6145802054053345 and Best Params:  {'optimizer': 'ftrl', 'no_neurons': 16, 'no_layers': 2, 'loss': 'huber', 'learning_rate': 0.1, 'batch_size': 64, 'activation_fn': 'relu'}\n",
      "MAE: 0.22193392795837744\n",
      "MSE: 0.07941234914828495\n",
      "RMSE: 0.2818019679638255\n",
      "R2: 0.4829840840168358\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_7={'no_layers':[nh['no_layers']],\n",
    "            'no_neurons':[nn['no_neurons']],\n",
    "            'optimizer':[op['optimizer']],\n",
    "            'learning_rate':[lr['learning_rate']],\n",
    "            'activation_fn':[af['activation_fn']],\n",
    "            'loss':[lo['loss']],\n",
    "            'batch_size':[16,32,64]}\n",
    "\n",
    "\n",
    "random_search_7 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_7,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_7 = random_search_7.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_7.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_7.best_params_)\n",
    "\n",
    "bs = random_search_results_7.best_params_\n",
    "\n",
    "y_test_7= random_search_results_7.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_7, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_7, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_7, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_7, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl',\n",
       " 'no_neurons': 16,\n",
       " 'no_layers': 2,\n",
       " 'loss': 'huber',\n",
       " 'learning_rate': 0.1,\n",
       " 'batch_size': 64,\n",
       " 'activation_fn': 'relu'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END activation_fn=relu, batch_size=64, epochs=10, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   1.5s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=64, epochs=10, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.616 total time=   2.0s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=64, epochs=10, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.620 total time=   1.6s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=64, epochs=10, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.616 total time=   1.6s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=64, epochs=10, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.581 total time=   1.6s\n",
      "[CV 1/5] END activation_fn=relu, batch_size=64, epochs=20, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.617 total time=   2.8s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=64, epochs=20, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.616 total time=   2.8s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=64, epochs=20, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.611 total time=   2.8s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=64, epochs=20, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.619 total time=   3.0s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=64, epochs=20, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.549 total time=   2.6s\n",
      "[CV 1/5] END activation_fn=relu, batch_size=64, epochs=30, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.561 total time=   3.8s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=64, epochs=30, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.627 total time=   4.0s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=64, epochs=30, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   3.8s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=64, epochs=30, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.598 total time=   4.0s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=64, epochs=30, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.579 total time=   4.4s\n",
      "[CV 1/5] END activation_fn=relu, batch_size=64, epochs=40, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.614 total time=   5.0s\n",
      "[CV 2/5] END activation_fn=relu, batch_size=64, epochs=40, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.609 total time=   4.8s\n",
      "[CV 3/5] END activation_fn=relu, batch_size=64, epochs=40, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.623 total time=   4.8s\n",
      "[CV 4/5] END activation_fn=relu, batch_size=64, epochs=40, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   4.8s\n",
      "[CV 5/5] END activation_fn=relu, batch_size=64, epochs=40, learning_rate=0.1, loss=huber, no_layers=2, no_neurons=16, optimizer=ftrl;, score=0.613 total time=   4.9s\n",
      "Best Score:  0.6145802054053345 and Best Params:  {'optimizer': 'ftrl', 'no_neurons': 16, 'no_layers': 2, 'loss': 'huber', 'learning_rate': 0.1, 'epochs': 40, 'batch_size': 64, 'activation_fn': 'relu'}\n",
      "MAE: 0.22193392795837744\n",
      "MSE: 0.07941234914828495\n",
      "RMSE: 0.2818019679638255\n",
      "R2: 0.4829840840168358\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "params_8={'no_layers':[nh['no_layers']],\n",
    "            'no_neurons':[nn['no_neurons']],\n",
    "            'optimizer':[op['optimizer']],\n",
    "            'learning_rate':[lr['learning_rate']],\n",
    "            'activation_fn':[af['activation_fn']],\n",
    "            'loss':[lo['loss']],\n",
    "            'batch_size':[bs['batch_size']], \n",
    "            'epochs':[10,20,30,40]}\n",
    "\n",
    "random_search_8 = RandomizedSearchCV(model,\n",
    "                                   param_distributions = params_8,\n",
    "                                   cv = KFold(5),verbose=5, scoring='r2')\n",
    "random_search_results_8 = random_search_8.fit(x_train_std, y_train)\n",
    "\n",
    "print(\"Best Score: \",\n",
    "      random_search_results_8.best_score_,\n",
    "      \"and Best Params: \",\n",
    "      random_search_results_8.best_params_)\n",
    "\n",
    "ep = random_search_results_8.best_params_\n",
    "\n",
    "y_test_8= random_search_results_8.predict(x_test_std)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test_8, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test_8, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test_8, y_test)))\n",
    "print('R2:',metrics.r2_score(y_test_8, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'ftrl',\n",
       " 'no_neurons': 16,\n",
       " 'no_layers': 2,\n",
       " 'loss': 'huber',\n",
       " 'learning_rate': 0.1,\n",
       " 'epochs': 40,\n",
       " 'batch_size': 64,\n",
       " 'activation_fn': 'relu'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Final Model\n",
    "We train the final model with the best hyperparameters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(learning_rate=ep['learning_rate'],activation_fn=ep['activation_fn'],no_layers=ep['no_layers'],no_neurons=ep['no_neurons'],loss=ep['loss'],optimizer=ep['optimizer']):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,activation=activation_fn))\n",
    "    for _ in range(no_layers):\n",
    "        model.add(Dense(no_neurons,activation=activation_fn))\n",
    "    model.add(Dense(1, activation = activation_fn))\n",
    "    opt = get_optimizer(optimizer,learning_rate)\n",
    "    model.compile(optimizer=opt,loss=loss,metrics = [tf.keras.metrics.RootMeanSquaredError()])    \n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KerasClassifier\n",
    "model = KerasRegressor(build_fn = new_model,\n",
    "                       epochs = ep['epochs'], \n",
    "                       batch_size = ep['batch_size'],\n",
    "                       verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Predict using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.22304601129160614\n",
      "MSE: 0.08075588454792985\n",
      "RMSE: 0.2841757986668285\n",
      "R2: 0.4604268588088657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20c41d06670>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1 = model.fit(x_train_std, y_train)\n",
    "y_pred = model.predict(x_test_std)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_pred, y_test))  \n",
    "print('MSE:', metrics.mean_squared_error(y_pred, y_test))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "print('R2:',metrics.r2_score(y_pred, y_test))\n",
    "\n",
    "plt.scatter(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model has a R-squared value of  48 %.\n",
    "Model Hyperparameters:-\n",
    "\n",
    "- Learning Rate: 0.1\n",
    "- Number of Layers: 2\n",
    "- Hidden Nodes in each layer:  [16, 16]\n",
    "- optimizer: 'ftrl'\n",
    "- activation: 'relu'\n",
    "- loss: 'huber'\n",
    "- batch size: 16\n",
    "- epochs: 40"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7fc959a8307d8cf79d2ed8c89ebfa7c82ec458660b8d766f351c26797af7941"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
